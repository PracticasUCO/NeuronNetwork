/*
 *  NeuronNetwork: A class collection to build neuron networks
 *  Copyright (C) 2014  Pedro Jos√© Piquero Plaza
 *
 *  This program is free software: you can redistribute it and/or modify
 *  it under the terms of the GNU General Public License as published by
 *  the Free Software Foundation, either version 3 of the License, or
 *  (at your option) any later version.
 *
 *  This program is distributed in the hope that it will be useful,
 *  but WITHOUT ANY WARRANTY; without even the implied warranty of
 *  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
 *  GNU General Public License for more details.
 *
 *  You should have received a copy of the GNU General Public License
 *  along with this program.  If not, see <http://www.gnu.org/licenses/>.
 */

package neuron_network;

import static org.junit.Assert.assertEquals;

import org.junit.Test;
import org.junit.Before;

import java.util.ArrayList;

public class SpreadOutTest {
	private MultilayerPerceptron _simple_xor;
	private MultilayerPerceptron _xor_1_layer;
	private MultilayerPerceptron _xor_2_layers;
	private ArrayList<Double> _zero_zero;
	private ArrayList<Double> _zero_one;
	private ArrayList<Double> _one_zero;
	private ArrayList<Double> _one_one;
	private double delta;

	@Before
	public void setUp() {
		_xor_1_layer = new MultilayerPerceptron(1, 2, 1);
		_xor_2_layers = new MultilayerPerceptron(2, 2, 1);
		_simple_xor = new MultilayerPerceptron(1, 1, 1);
		_zero_zero = new ArrayList<Double>();
		_zero_one = new ArrayList<Double>();
		_one_zero = new ArrayList<Double>();
		_one_one = new ArrayList<Double>();

		_zero_zero.add(0D);
		_zero_zero.add(0D);
		_zero_one.add(0D);
		_zero_one.add(1D);
		_one_zero.add(1D);
		_one_zero.add(0D);
		_one_one.add(1D);
		_one_one.add(1D);

		delta = 1e-10;
	}

	@Test
	public void checkSpreadOutWithZeroZero() {
		_simple_xor.feed(_zero_zero);
		_simple_xor.spreadOut();

		_xor_1_layer.feed(_zero_zero);
		_xor_1_layer.spreadOut();

		_xor_2_layers.feed(_zero_zero);
		_xor_2_layers.spreadOut();

		double simpleOutput = _simple_xor.getOutputs().get(0);
		double xor1Output = _xor_1_layer.getOutputs().get(0);
		double xor2Output = _xor_2_layers.getOutputs().get(0);

		assertEquals(0.6224593312, simpleOutput, delta);
		assertEquals(0.7310585786, xor1Output, delta);
		assertEquals(0.8118562749, xor2Output, delta);
	}

	@Test
	public void checkSpreadOutWithZeroOne() {
		_simple_xor.feed(_zero_one);
		_simple_xor.spreadOut();

		_xor_1_layer.feed(_zero_one);
		_xor_1_layer.spreadOut();

		_xor_2_layers.feed(_zero_one);
		_xor_2_layers.spreadOut();

		double simpleOutput = _simple_xor.getOutputs().get(0);
		double xor1Output = _xor_1_layer.getOutputs().get(0);
		double xor2Output = _xor_2_layers.getOutputs().get(0);

		assertEquals(0.6750375273, simpleOutput, delta);
		assertEquals(0.8118562749, xor1Output, delta);
		assertEquals(0.8353064996, xor2Output, delta);
	}

	@Test
	public void checkSpreadOutWithOneZero() {
		_simple_xor.feed(_one_zero);
		_simple_xor.spreadOut();

		_xor_1_layer.feed(_one_zero);
		_xor_1_layer.spreadOut();

		_xor_2_layers.feed(_one_zero);
		_xor_2_layers.spreadOut();

		double simpleOutput = _simple_xor.getOutputs().get(0);
		double xor1Output = _xor_1_layer.getOutputs().get(0);
		double xor2Output = _xor_2_layers.getOutputs().get(0);

		assertEquals(0.6750375273, simpleOutput, delta);
		assertEquals(0.8118562749, xor1Output, delta);
		assertEquals(0.8353064996, xor2Output, delta);
	}

	@Test
	public void checkSpreadOutWithOneOne() {
		_simple_xor.feed(_one_one);
		_simple_xor.spreadOut();

		_xor_1_layer.feed(_one_one);
		_xor_1_layer.spreadOut();

		_xor_2_layers.feed(_one_one);
		_xor_2_layers.spreadOut();

		double simpleOutput = _simple_xor.getOutputs().get(0);
		double xor1Output = _xor_1_layer.getOutputs().get(0);
		double xor2Output = _xor_2_layers.getOutputs().get(0);

		assertEquals(0.7069873680, simpleOutput, delta);
		assertEquals(0.8534092045, xor1Output, delta);
		assertEquals(0.8464231617, xor2Output, delta);
	}

	@Test
	public void checkSpreadOutInABigNetwork() {
		MultilayerPerceptron mp = new MultilayerPerceptron(20, 20, 3);
		ArrayList<Double> inputs = new ArrayList<Double>();

		inputs.add(-1D);
		inputs.add(-2D);
		inputs.add(0D);
		inputs.add(1D);
		inputs.add(2D);

		final double expectedOutput0 = 0.9999999979;
		final double expectedOutput1 = 0.9999999979;
		final double expectedOutput2 = 0.9999999979;

		mp.feed(inputs);
		mp.spreadOut();

		double mpOutput0 = mp.getOutputs().get(0);
		double mpOutput1 = mp.getOutputs().get(1);
		double mpOutput2 = mp.getOutputs().get(2);

		assertEquals(expectedOutput0, mpOutput0, delta);
		assertEquals(expectedOutput1, mpOutput1, delta);
		assertEquals(expectedOutput2, mpOutput2, delta);
	}

	@Test
	public void checkSpreadOutDontAffectOutputNetworkSize() {
		_simple_xor.feed(_one_one);
		_xor_1_layer.feed(_one_one);
		_xor_2_layers.feed(_one_one);

		_simple_xor.spreadOut();
		_xor_1_layer.spreadOut();
		_xor_2_layers.spreadOut();

		assertEquals(1, _simple_xor.getOutputLayerSize());
		assertEquals(1, _xor_1_layer.getOutputLayerSize());
		assertEquals(1, _xor_2_layers.getOutputLayerSize());
	}

	@Test
	public void checkConsistentOfGetOutputsSizeAfterSpreadOut() {
		_simple_xor.feed(_one_one);
		_xor_1_layer.feed(_one_one);
		_xor_2_layers.feed(_one_one);

		_simple_xor.spreadOut();
		_xor_1_layer.spreadOut();
		_xor_2_layers.spreadOut();

		assertEquals(_simple_xor.getOutputs().size(),
				_simple_xor.getOutputLayerSize());
		assertEquals(_xor_1_layer.getOutputs().size(),
				_xor_1_layer.getOutputLayerSize());
		assertEquals(_xor_2_layers.getOutputs().size(),
				_xor_2_layers.getOutputLayerSize());
	}
}